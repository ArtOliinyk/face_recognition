{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries and Startup Necessities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.transform import resize\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.applications.mobilenet import preprocess_input as preprocess_input_v1, decode_predictions as decode_predictions_v1\n",
    "from keras.applications.resnet import preprocess_input as preprocess_input_resnet, decode_predictions as decode_predictions_resnet\n",
    "from keras.utils import load_img, img_to_array, to_categorical\n",
    "from keras.applications import MobileNet, ResNet50\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam, AdamW, RMSprop, SGD\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "# from keras.metrics import Accuracy\n",
    "from tensorflow.keras.metrics import F1Score\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from wandb.integration.keras import WandbMetricsLogger\n",
    "import wandb\n",
    "# from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Kaggle Secret to store my Wandb API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from kaggle_secrets import UserSecretsClient\n",
    "# user_secrets = UserSecretsClient()\n",
    "# secret_value_0 = user_secrets.get_secret(\"wandb_api\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Login to Wandb using my own Wandb API Key stored on Kaggle Secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: art-oliynyk1 (artoliinyk). Use `wandb login --relogin` to force relogin\n",
      "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\artem\\_netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key='81478a6190ee7d65e15acfbf7f02038452ed97ae')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset and Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_NAMES = \"./lfw-dataset/lfw_allnames.csv\"\n",
    "IMAGES_SRC = \"./lfw-dataset/lfw-deepfunneled/lfw-deepfunneled\"\n",
    "PEOPLE = \"./lfw-dataset/people.csv\"\n",
    "PEOPLE_TEST = \"./lfw-dataset/peopleDevTest.csv\"\n",
    "PEOPLE_TRAIN = \"./lfw-dataset/peopleDevTrain.csv\"\n",
    "README = \"./lfw-dataset/lfw_readme.csv\"\n",
    "WORK_DIR = \"./working/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5749.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.301792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.016410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>530.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            images\n",
       "count  5749.000000\n",
       "mean      2.301792\n",
       "std       9.016410\n",
       "min       1.000000\n",
       "25%       1.000000\n",
       "50%       1.000000\n",
       "75%       2.000000\n",
       "max     530.000000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.read_csv(ALL_NAMES)\n",
    "df_all = df_all.sort_values(by=\"images\", ascending=False) # Descending\n",
    "df_all.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see on the dataframe description above, the maximum data is 530 but the 3rd quartile is 2. This indicate a highly imbalance data. So, I would like to filter only use the data whose images count is > 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all[df_all[\"images\"] > 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of unique names: 12\n",
      "Count of all data: 1560\n"
     ]
    }
   ],
   "source": [
    "unique_name_count = df_all['name'].nunique()\n",
    "\n",
    "# Display the count of unique values in the \"name\" column\n",
    "print(\"Count of unique names:\", unique_name_count)\n",
    "print(\"Count of all data:\", df_all[\"images\"].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this only gives us 7 classes/names after filtering, with total data 1288."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data set. This step follows the reference: https://keras.io/api/applications/#classify-imagenet-classes-with-resnet50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|                                                                                           | 0/12 [00:00<?, ?it/s]██████▉                                                                            | 1/12 [00:03<00:38,  3.49s/it]█████████████▊                                                                     | 2/12 [00:04<00:22,  2.28s/it]████████████████████▊                                                              | 3/12 [00:05<00:15,  1.70s/it]███████████████████████████▋                                                       | 4/12 [00:06<00:10,  1.29s/it]██████████████████████████████████▌                                                | 5/12 [00:07<00:07,  1.07s/it]█████████████████████████████████████████▌                                         | 6/12 [00:07<00:05,  1.15it/s]████████████████████████████████████████████████▍                                  | 7/12 [00:08<00:03,  1.40it/s]███████████████████████████████████████████████████████▎                           | 8/12 [00:08<00:02,  1.71it/s]██████████████████████████████████████████████████████████████▎                    | 9/12 [00:08<00:01,  1.97it/s]████████████████████████████████████████████████████████████████████▎             | 10/12 [00:09<00:00,  2.23it/s]███████████████████████████████████████████████████████████████████████████▏      | 11/12 [00:09<00:00,  2.44it/s]██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:09<00:00,  2.53it/s]██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:09<00:00,  1.23it/s]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "tqdm_all_names = tqdm(list(df_all[\"name\"]), colour=\"blue\")\n",
    "\n",
    "for name in tqdm_all_names:\n",
    "    dir_path = os.path.join(IMAGES_SRC, name)\n",
    "    list_images_name = os.listdir(dir_path)\n",
    "    \n",
    "    for image_name in list_images_name:\n",
    "        images_path = os.path.join(dir_path, image_name)\n",
    "        rgb_image = load_img(images_path, target_size=(224, 224))\n",
    "        x = img_to_array(rgb_image)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x_v1 = preprocess_input_v1(x)\n",
    "        X.append(x_v1)\n",
    "        Y.append(name)\n",
    "\n",
    "X = np.asarray(X)\n",
    "Y = np.asarray(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use one-hot encoding to transform out label from text to number so the machine could understand it. One-hot encoder is used because the MobileNet requires for each label to be a list of its classes, much like sparse-encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the data\n",
    "encoded_Y = encoder.fit_transform(Y.reshape(-1, 1))\n",
    "encoded_Y = encoded_Y.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1560, 12)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Dev-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train : Dev : Test = 70 : 15 : 15\n",
    "\n",
    "I tried to use stratify=Y_temp on `X_dev, X_test, Y_dev, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=30, stratify=Y_temp)` but it showed error \"The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.\"\n",
    "\n",
    "So I use the regular `train_test_split` function from Scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_temp, Y1_train, Y1_temp = train_test_split(X, encoded_Y, test_size=0.3, random_state=30)\n",
    "X1_dev, X1_test, Y1_dev, Y1_test = train_test_split(X1_temp, Y1_temp, test_size=0.5, random_state=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I try to reshape the resulting dimension to be of (n_samples, 224, 224, 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1_train shape: (1092, 224, 224, 3)\n",
      "X1_dev shape: (234, 224, 224, 3)\n",
      "X1_test shape: (234, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "NEW_SHAPE = (-1, 224, 224, 3)\n",
    "X1_train = X1_train.reshape(NEW_SHAPE)\n",
    "X1_dev = X1_dev.reshape(NEW_SHAPE)\n",
    "X1_test = X1_test.reshape(NEW_SHAPE)\n",
    "print(\"X1_train shape:\", X1_train.shape)\n",
    "print(\"X1_dev shape:\", X1_dev.shape)\n",
    "print(\"X1_test shape:\", X1_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y1_train shape: (1092, 12)\n",
      "Y1_dev shape: (234, 12)\n",
      "Y1_test shape: (234, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"Y1_train shape:\", Y1_train.shape)\n",
    "print(\"Y1_dev shape:\", Y1_dev.shape)\n",
    "print(\"Y1_test shape:\", Y1_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mpimg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, img_path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(X[:\u001b[38;5;241m5\u001b[39m]):\n\u001b[1;32m----> 4\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mmpimg\u001b[49m\u001b[38;5;241m.\u001b[39mimread(img_path)\n\u001b[0;32m      5\u001b[0m     axs[i]\u001b[38;5;241m.\u001b[39mimshow(img)\n\u001b[0;32m      6\u001b[0m     axs[i]\u001b[38;5;241m.\u001b[39mset_title(selected_images[i]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m])  \u001b[38;5;66;03m# Title with the person's name\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mpimg' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig, axs = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for i, img_path in enumerate(X[:5]):\n",
    "    img = mpimg.imread(img_path)\n",
    "    axs[i].imshow(img)\n",
    "    axs[i].set_title(selected_images[i].split('/')[-2])  # Title with the person's name\n",
    "    axs[i].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Declaration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the base model, I use MobileNet with \"imagenet\" as the initial weights. The base model is loaded without its classifier head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
      "17225924/17225924 ━━━━━━━━━━━━━━━━━━━━ 0s 0s/ste ━━━━━━━━━━━━━━━━━━━━ 1:12 4us/st ━━━━━━━━━━━━━━━━━━━━ 1:05 4us/st ━━━━━━━━━━━━━━━━━━━━ 1:02 4us/st ━━━━━━━━━━━━━━━━━━━━ 46s 3us/step ━━━━━━━━━━━━━━━━━━━━ 40s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 34s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 26s 2us/ste ━━━━━━━━━━━━━━━━━━━━ 22s 1us/ste ━━━━━━━━━━━━━━━━━━━━ 17s 1us/ste ━━━━━━━━━━━━━━━━━━━━ 13s 1us/ste ━━━━━━━━━━━━━━━━━━━━ 10s 1us/ste ━━━━━━━━━━━━━━━━━━━━ 7s 1us/ste ━━━━━━━━━━━━━━━━━━━━ 5s 0us/st ━━━━━━━━━━━━━━━━━━━━ 4s 0us/st ━━━━━━━━━━━━━━━━━━━━ 3s 0us/st ━━━━━━━━━━━━━━━━━━━━ 2s 0us/st ━━━━━━━━━━━━━━━━━━━━ 1s 0us/st ━━━━━━━━━━━━━━━━━━━━ 0s 0us/st ━━━━━━━━━━━━━━━━━━━━ 0s 0us/st ━━━━━━━━━━━━━━━━━━━━ 0s 0us/st ━━━━━━━━━━━━━━━━━━━━ 0s 0us/st ━━━━━━━━━━━━━━━━━━━━ 1s 0us/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "object __array__ method not producing an array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mobilenet_mdl \u001b[38;5;241m=\u001b[39m \u001b[43mMobileNet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimagenet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\applications\\mobilenet.py:269\u001b[0m, in \u001b[0;36mMobileNet\u001b[1;34m(input_shape, alpha, depth_multiplier, dropout, include_top, weights, input_tensor, pooling, classes, classifier_activation, name)\u001b[0m\n\u001b[0;32m    265\u001b[0m         weight_path \u001b[38;5;241m=\u001b[39m BASE_WEIGHT_PATH \u001b[38;5;241m+\u001b[39m model_name\n\u001b[0;32m    266\u001b[0m         weights_path \u001b[38;5;241m=\u001b[39m file_utils\u001b[38;5;241m.\u001b[39mget_file(\n\u001b[0;32m    267\u001b[0m             model_name, weight_path, cache_subdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    268\u001b[0m         )\n\u001b[1;32m--> 269\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    271\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_weights(weights)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:108\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    106\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    107\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: object __array__ method not producing an array"
     ]
    }
   ],
   "source": [
    "mobilenet_mdl = MobileNet(\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3),\n",
    "    weights=\"imagenet\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.RandomFlip('horizontal'),\n",
    "  tf.keras.layers.RandomContrast(factor=0.2),\n",
    "  tf.keras.layers.RandomBrightness(factor=0.3),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, add a custom classifier head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def head_model(base_model, n_classes):\n",
    "    inputs = base_model.input\n",
    "    aug = data_augmentation(inputs)\n",
    "    top_model = base_model.output\n",
    "    top_model = GlobalAveragePooling2D(data_format=\"channels_last\")(top_model)\n",
    "    top_model = Dense(1024, activation=\"relu\")(top_model)\n",
    "    top_model = Dropout(0.69)(top_model)\n",
    "    top_model = Dense(1000, activation=\"relu\")(top_model)\n",
    "    top_model = Dropout(0.55)(top_model)\n",
    "    top_model = Dense(n_classes, activation=\"softmax\")(top_model)\n",
    "    return top_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stack the classifier head on the top of the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mobilenet_head = head_model(mobilenet_mdl, encoded_Y.shape[1])\n",
    "model_mobilenet = Model(inputs = mobilenet_mdl.input, outputs = model_mobilenet_head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeze other than the top 6 layers (or, train the classifier heads), so that the trainable neurons is the one on the custom classifier head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_mobilenet.layers[:-6]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the declared model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mobilenet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the trainable params/neurons above is the same as the sum of the number of neurons from the last 6 layers. This indicates that we have freezed the base model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create helper function to plot the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    # Plot training and validation accuracy values\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['f1_score'], label='Training')\n",
    "    plt.plot(history.history['val_f1_score'], label='Validation')\n",
    "    plt.title('Training and Validation F1 Score')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot training and validation loss values\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training')\n",
    "    plt.plot(history.history['val_loss'], label='Validation')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create helper function to warmup learning rate while training. This help the model to utilize high learning rate for a few epochs, then exponentially decrease the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(running_epoch, learning_rate):\n",
    "    try:\n",
    "        if running_epoch <= 10:\n",
    "            return learning_rate\n",
    "        else:\n",
    "            if learning_rate < float(1e-6): # Do NOT make the learning rate any lower than 1e-6\n",
    "                return learning_rate\n",
    "            else:\n",
    "                return learning_rate * tf.math.exp(-0.1)\n",
    "    except Exception as e:\n",
    "        print(f\"Error while returning the scheduler LR!\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create helper function to show time elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_time_elapsed(elapsed_time):\n",
    "    # Format the elapsed time\n",
    "    hours, remainder = divmod(elapsed_time, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "\n",
    "    if hours >= 1:\n",
    "        print(f\"The training goes by {int(hours)} hour, {int(minutes)} minutes, and {int(seconds)} seconds.\")\n",
    "    elif minutes >= 1:\n",
    "        print(f\"The training goes by {int(minutes)} minutes and {int(seconds)} seconds.\")\n",
    "    else:\n",
    "        print(f\"The training goes by {int(seconds)} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase I: Train the Classifier Head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing Wandb for Phase I - Train and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize WandB\n",
    "wandb.init(\n",
    "    project=\"face-recognition-lfw\",\n",
    "    name=\"phase1-train-n-validate\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describing hyperparameters used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters Phase 1\n",
    "BATCH_SIZE_phase1 = 64\n",
    "EPOCHS_phase1 = 150\n",
    "LEARNING_RATE_phase1 = 3e-4\n",
    "L2_REGULARIZATION_phase1 = 4e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describing loss function, optimizer, and metrics used when training the model. I use F1-Score because of the imbalance dataset case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_mobilenet_phase1 = AdamW(\n",
    "    learning_rate=LEARNING_RATE_phase1,\n",
    "    weight_decay=L2_REGULARIZATION_phase1,\n",
    ")\n",
    "loss_function_mobilenet_phase1 = CategoricalCrossentropy()\n",
    "early_stopping_phase1 = EarlyStopping(monitor='val_f1_score', mode=\"max\", start_from_epoch=10, patience=25, restore_best_weights=True)\n",
    "scheduler_phase1 = LearningRateScheduler(scheduler)\n",
    "wandb_phase1 = WandbMetricsLogger(save_model=False)\n",
    "\n",
    "model_mobilenet.compile(\n",
    "    loss = loss_function_mobilenet_phase1,\n",
    "    optimizer = optimizer_mobilenet_phase1,\n",
    "    metrics=[F1Score(average=\"micro\", dtype=np.float32)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"Training MobileNet Phase 1...\")\n",
    "    start_time1 = time.time()\n",
    "    training_history = model_mobilenet.fit(\n",
    "        batch_size=BATCH_SIZE_phase1,\n",
    "        epochs=EPOCHS_phase1,\n",
    "        x=X1_train,\n",
    "        y=Y1_train,\n",
    "        shuffle=True,\n",
    "        validation_data=(X1_dev, Y1_dev),\n",
    "        callbacks=[\n",
    "            early_stopping_phase1,\n",
    "            scheduler_phase1,\n",
    "            wandb_phase1,\n",
    "        ],\n",
    "        verbose=0 if EPOCHS_phase1 > 50 else 1,\n",
    "    )\n",
    "    elapsed_time1 = time.time() - start_time1\n",
    "    \n",
    "    plot_training_history(training_history)\n",
    "    training_time_elapsed(elapsed_time1)\n",
    "except Exception as e:\n",
    "    print(\"Error while training MobileNet!\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the first phase using development data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_eval_mobilenet_phase1 = model_mobilenet.evaluate(X1_dev, Y1_dev, batch_size=BATCH_SIZE_phase1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"F1 Score of the MobileNet Phase 1: {round(result_eval_mobilenet_phase1[1] * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting validation vs training F1-Score and its loss is looking good! No sign of overfitting. The initial Phase I training validation F1-Score is 90s%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finish the current Wandb logging run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase II: Train the 2 Top MobileNet Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize new Wandb run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize WandB\n",
    "wandb.init(\n",
    "    project=\"face-recognition-lfw\",\n",
    "    name=\"phase2-train-n-validate\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Base model has {len(mobilenet_mdl.layers)} layers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I want to train the 2 top MobileNet Convolutional Layers. Unfreeze starting from the 2 top MobileNet Convolutional Layers, and freeze the other layers. This means we unfreeze the last 2 Convolutional Layers (Conv2D), all the way to the last layers. The previous layers should be freezed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_mobilenet.layers[:len(model_mobilenet.layers)-15]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "for layer in model_mobilenet.layers[len(model_mobilenet.layers)-15:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters Phase 2\n",
    "BATCH_SIZE_phase2 = 32\n",
    "EPOCHS_phase2 = 100\n",
    "LEARNING_RATE_phase2 = 1e-4\n",
    "L2_REGULARIZATION_phase2 = 4e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_mobilenet_phase2 = AdamW(\n",
    "    learning_rate=LEARNING_RATE_phase2,\n",
    "    weight_decay=L2_REGULARIZATION_phase2\n",
    ")\n",
    "loss_function_mobilenet_phase2 = CategoricalCrossentropy()\n",
    "early_stopping_phase2 = EarlyStopping(monitor='val_f1_score', mode=\"max\", start_from_epoch=10, patience=25, restore_best_weights=True)\n",
    "scheduler_phase2 = LearningRateScheduler(scheduler)\n",
    "wandb_phase2 = WandbMetricsLogger(save_model=False)\n",
    "\n",
    "model_mobilenet.compile(\n",
    "    loss = loss_function_mobilenet_phase2,\n",
    "    optimizer = optimizer_mobilenet_phase2,\n",
    "    metrics=[F1Score(average=\"micro\", dtype=np.float32)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"Training MobileNet Phase 2...\")\n",
    "    start_time1 = time.time()\n",
    "    training_history = model_mobilenet.fit(\n",
    "        batch_size=BATCH_SIZE_phase2,\n",
    "        epochs=EPOCHS_phase2,\n",
    "        x=X1_train,\n",
    "        y=Y1_train,\n",
    "        shuffle=True,\n",
    "        validation_data=(X1_dev, Y1_dev),\n",
    "        callbacks=[\n",
    "            early_stopping_phase2,\n",
    "            scheduler_phase2,\n",
    "            wandb_phase2,\n",
    "        ],\n",
    "        verbose=0 if EPOCHS_phase2 > 50 else 1,\n",
    "    )\n",
    "    elapsed_time1 = time.time() - start_time1\n",
    "    \n",
    "    plot_training_history(training_history)\n",
    "    training_time_elapsed(elapsed_time1)\n",
    "except Exception as e:\n",
    "    print(\"Error while training MobileNet!\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the second phase with development data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_eval_mobilenet_phase2 = model_mobilenet.evaluate(X1_dev, Y1_dev, batch_size=BATCH_SIZE_phase2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"F1 Score of the MobileNet Phase 2: {round(result_eval_mobilenet_phase2[1] * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting training vs validation loss and F1-Score graphs are looking good! No sign of overfitting. The evaluation of the 2nd Phase is the F1-Score of 95s%. This implicates that training the classifier head first then train the 2 last Convolutional Layers improves the resulting F1-Score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finish the current Wandb logging run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holdout Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use holdout strategy here. I'm going to combine the training and validation/development data to create a new \"holdout\" data. This holdout data is going to be tested against the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the arrays along the first axis\n",
    "X1_holdout = np.concatenate((X1_train, X1_dev), axis=0)\n",
    "Y1_holdout = np.concatenate((Y1_train, Y1_dev), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase I: Train the Classifier Head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize new Wandb logging run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize WandB\n",
    "wandb.init(\n",
    "    project=\"face-recognition-lfw\",\n",
    "    name=\"phase1-holdout\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-freeze the model's layers except the last 6 layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_mobilenet.layers[:-6]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define hyperparameters for holdout phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters holdout Phase 1\n",
    "BATCH_SIZE_holdout_phase1 = 32\n",
    "EPOCHS_holdout_phase1 = 20\n",
    "LEARNING_RATE_holdout_phase1 = 2e-4\n",
    "L2_REGULARIZATION_holdout_phase1 = 4e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the loss function, optimizer, callback functions, and compile the model again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_mobilenet_holdout_phase1 = AdamW(\n",
    "    learning_rate=LEARNING_RATE_holdout_phase1,\n",
    "    weight_decay=L2_REGULARIZATION_holdout_phase1\n",
    ")\n",
    "loss_function_mobilenet_holdout_phase1 = CategoricalCrossentropy()\n",
    "early_stopping_holdout_phase1 = EarlyStopping(monitor='val_f1_score', mode=\"max\", start_from_epoch=10, patience=25, restore_best_weights=True)\n",
    "scheduler_holdout_phase1 = LearningRateScheduler(scheduler)\n",
    "wandb_holdout_phase1 = WandbMetricsLogger(save_model=False)\n",
    "\n",
    "model_mobilenet.compile(\n",
    "    loss = loss_function_mobilenet_holdout_phase1,\n",
    "    optimizer = optimizer_mobilenet_holdout_phase1,\n",
    "    metrics=[\n",
    "        F1Score(average=\"micro\", dtype=np.float32),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-train the model using Holdout data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"Training MobileNet Holdout Phase 1...\")\n",
    "    start_time1 = time.time()\n",
    "    training_history = model_mobilenet.fit(\n",
    "        batch_size=BATCH_SIZE_holdout_phase1,\n",
    "        epochs=EPOCHS_holdout_phase1,\n",
    "        x=X1_holdout,\n",
    "        y=Y1_holdout,\n",
    "        shuffle=True,\n",
    "        validation_data=(X1_test, Y1_test),\n",
    "        callbacks=[\n",
    "            early_stopping_holdout_phase1,\n",
    "            scheduler_holdout_phase1,\n",
    "            wandb_holdout_phase1,\n",
    "        ],\n",
    "        verbose=0,\n",
    "    )\n",
    "    elapsed_time1 = time.time() - start_time1\n",
    "    \n",
    "    plot_training_history(training_history)\n",
    "    training_time_elapsed(elapsed_time1)\n",
    "except Exception as e:\n",
    "    print(\"Error while training MobileNet!\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_eval_mobilenet_holdout_phase1 = model_mobilenet.evaluate(X1_test, Y1_test, batch_size=BATCH_SIZE_holdout_phase1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"F1 Score of the MobileNet Holdout Phase 1: {round(result_eval_mobilenet_holdout_phase1[1] * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finish the current Wandb logging run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase II: Train the 2 Top MobileNet Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a new Wandb logging run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize WandB\n",
    "wandb.init(\n",
    "    project=\"face-recognition-lfw\",\n",
    "    name=\"phase2-holdout\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfreeze the base model/MobileNet model except the 2 last Convolutional layers and keep the other layers to be frozen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_mobilenet.layers[:len(model_mobilenet.layers)-15]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "for layer in model_mobilenet.layers[len(model_mobilenet.layers)-15:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the hyperparameters used for Phase 2 of the holdout training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters holdout Phase 2\n",
    "BATCH_SIZE_holdout_phase2 = 32\n",
    "EPOCHS_holdout_phase2 = 100\n",
    "LEARNING_RATE_holdout_phase2 = 1e-4\n",
    "L2_REGULARIZATION_holdout_phase2 = 4e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-compile the model again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_mobilenet_holdout_phase2 = AdamW(\n",
    "    learning_rate=LEARNING_RATE_holdout_phase2,\n",
    "    weight_decay=L2_REGULARIZATION_holdout_phase2\n",
    ")\n",
    "loss_function_mobilenet_holdout_phase2 = CategoricalCrossentropy()\n",
    "early_stopping_holdout_phase2 = EarlyStopping(monitor='val_f1_score', mode=\"max\", start_from_epoch=10, patience=20, restore_best_weights=True)\n",
    "scheduler_holdout_phase2 = LearningRateScheduler(scheduler)\n",
    "wandb_holdout_phase2 = WandbMetricsLogger(save_model=False)\n",
    "\n",
    "model_mobilenet.compile(\n",
    "    loss = loss_function_mobilenet_holdout_phase2,\n",
    "    optimizer = optimizer_mobilenet_holdout_phase2,\n",
    "    metrics=[\n",
    "        F1Score(average=\"micro\", dtype=np.float32),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"Training MobileNet Holdout Phase 2...\")\n",
    "    start_time1 = time.time()\n",
    "    training_history = model_mobilenet.fit(\n",
    "        batch_size=BATCH_SIZE_holdout_phase2,\n",
    "        epochs=EPOCHS_holdout_phase2,\n",
    "        x=X1_holdout,\n",
    "        y=Y1_holdout,\n",
    "        shuffle=True,\n",
    "        validation_data=(X1_test, Y1_test),\n",
    "        callbacks=[\n",
    "            early_stopping_holdout_phase2,\n",
    "            scheduler_holdout_phase2,\n",
    "            wandb_holdout_phase2\n",
    "        ],\n",
    "        verbose=0 if EPOCHS_holdout_phase2 > 50 else 1,\n",
    "    )\n",
    "    elapsed_time1 = time.time() - start_time1\n",
    "    \n",
    "    plot_training_history(training_history)\n",
    "    training_time_elapsed(elapsed_time1)\n",
    "except Exception as e:\n",
    "    print(\"Error while training MobileNet!\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the holdout Phase 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_eval_mobilenet_holdout_phase2 = model_mobilenet.evaluate(X1_test, Y1_test, batch_size=BATCH_SIZE_holdout_phase2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"F1 Score of the MobileNet Holdout Phase 2: {round(result_eval_mobilenet_holdout_phase2[1] * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalize the current Wandb logging run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Report & Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect() # garbage collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it using the unseen testing data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_mobilenet = model_mobilenet.evaluate(X1_test, Y1_test, batch_size=BATCH_SIZE_holdout_phase2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"F1 Score MobileNet: {round(result_mobilenet[1] * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is pretty good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_mobilenet = model_mobilenet.predict(X1_test, batch_size=BATCH_SIZE_holdout_phase2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_1dim = np.argmax(predict_mobilenet, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_1dim = np.argmax(Y1_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true = Y_test_1dim, y_pred = Y_pred_1dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.categories_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrice = confusion_matrix(y_true = Y_test_1dim, y_pred = Y_pred_1dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a color map (blue for higher values, red for lower values)\n",
    "cmap = sns.diverging_palette(240, 10, as_cmap=True)\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrice, annot=True, fmt=\".2f\", cmap=cmap, linewidths=.5, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_accuracy = accuracy_score(y_true=Y_test_1dim, y_pred=Y_pred_1dim)\n",
    "final_f1_score = f1_score(y_true=Y_test_1dim, y_pred=Y_pred_1dim, average=\"micro\")\n",
    "\n",
    "print(f\"Final Accuracy: {round(final_accuracy * 100, 2)}%\")\n",
    "print(f\"Final F1 Score: {round(final_f1_score * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = encoder.categories_[0]\n",
    "for i_test in range(len(Y_test_1dim)):\n",
    "    data_in_true = Y_test_1dim[i_test]\n",
    "    data_in_pred = Y_pred_1dim[i_test]\n",
    "    \n",
    "    if data_in_true != data_in_pred:\n",
    "        print(f\"True label: {true_labels[data_in_true]}\")\n",
    "        print(f\"Predicted: {true_labels[data_in_pred]}\")\n",
    "        print(\"===========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the falsely predicted label above and its supposed-to-be-true label. Then, we compare it with the most data from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.sort_values(by=\"images\", ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HA! As expected, our model tends to classify the images as the class that has the largest amount of data: **George W Bush**, **Colin Powell**, and **Tony Blair**.\n",
    "\n",
    "We could add more data to the other classes to balance them out, or we could implement augmentation techniques to add more data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Wandb again to log the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize WandB\n",
    "run = wandb.init(\n",
    "    project=\"face-recognition-lfw\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"mobilenet_facerecognition.keras\"\n",
    "model_mobilenet.save(os.path.join(WORK_DIR, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artifact = wandb.Artifact(\n",
    "  name=filename, \n",
    "  type=\"model\"\n",
    ")\n",
    "model_artifact.add_file(os.path.join(WORK_DIR, filename))\n",
    "run.log_artifact(model_artifact)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 26922,
     "sourceId": 34595,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30636,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
